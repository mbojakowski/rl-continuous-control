{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "You are welcome to use this coding environment to train your agent for the project.  Follow the instructions below to get started!\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtensorflow 1.7.1 has requirement numpy>=1.13.3, but you'll have numpy 1.12.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mipython 6.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.15, but you'll have prompt-toolkit 3.0.19 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environments corresponding to both versions of the environment are already saved in the Workspace and can be accessed at the file paths provided below.  \n",
    "\n",
    "Please select one of the two options below for loading the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "# select this option to load version 1 (with a single agent) of the environment\n",
    "env = UnityEnvironment(file_name='/data/Reacher_One_Linux_NoVis/Reacher_One_Linux_NoVis.x86_64')\n",
    "\n",
    "# select this option to load version 2 (with 20 agents) of the environment\n",
    "# env = UnityEnvironment(file_name='/data/Reacher_Linux_NoVis/Reacher.x86_64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Size of each action: 4\n",
      "There are 1 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "   1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   5.75471878e+00  -1.00000000e+00\n",
      "   5.55726671e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "  -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Note that **in this coding environment, you will not be able to watch the agents while they are training**, and you should set `train_mode=True` to restart the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnityEnvironmentException",
     "evalue": "No Unity environment is loaded.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnityEnvironmentException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-cda1a2f23cff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[0;34m]\u001b[0m      \u001b[0;31m# reset the environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_observations\u001b[0m                  \u001b[0;31m# get the current state (for each agent)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_agents\u001b[0m\u001b[0;34m)\u001b[0m                          \u001b[0;31m# initialize the score (for each agent)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_agents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# select an action (for each agent)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, train_mode, config, lesson)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mUnityEnvironmentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No Unity environment is loaded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mvector_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAllBrainInfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnityEnvironmentException\u001b[0m: No Unity environment is loaded."
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name]      # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  A few **important notes**:\n",
    "- When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```\n",
    "- To structure your work, you're welcome to work directly in this Jupyter notebook, or you might like to start over with a new file!  You can see the list of files in the workspace by clicking on **_Jupyter_** in the top left corner of the notebook.\n",
    "- In this coding environment, you will not be able to watch the agents while they are training.  However, **_after training the agents_**, you can download the saved model weights to watch the agents on your own machine! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Policy network\n",
    "# It will take as input a vector of 33 elements, and output an action vector, which we normalize with tanh\n",
    "# to clip vector elements between -1 and 1, as expected by the environment, which makes sense, as otherwise we\n",
    "# would need to know about the concrete \"physical\" values behind each action value, but the environment acts as\n",
    "# a black box for us.\n",
    "class Policy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Policy, self).__init__()\n",
    "        self.hidden1 = nn.Sequential(\n",
    "            nn.Linear(33, 400),\n",
    "            ##nn.BatchNorm1d(400),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Linear(400, 300),\n",
    "            ##nn.BatchNorm1d(300),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(300, 4),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden2(x)\n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Critic network\n",
    "# Here, we have a continuous action space, so the critic cannot output Q-value estimates given a state,\n",
    "# and instead has to take both state and action as input, and output a scalar Q-value estimate.\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Critic, self).__init__()\n",
    "        self.hidden1s = nn.Sequential(\n",
    "            nn.Linear(33, 100),\n",
    "            nn.ReLU()\n",
    "            #nn.BatchNorm1d(200)\n",
    "        ) \n",
    "        self.hidden1 = nn.Sequential(\n",
    "            nn.Linear(100+4, 300),\n",
    "            #nn.BatchNorm1d(300),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Linear(300, 100),\n",
    "            #nn.BatchNorm1d(100),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(100, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, state, action):\n",
    "        xs = self.hidden1s(state.float())\n",
    "        x = self.hidden1(torch.cat((xs, action), dim=1))\n",
    "        x = self.hidden2(x)\n",
    "        #x = self.hidden1s(state.float())\n",
    "        #x = self.hidden1(torch.cat((x, action), dim=1))\n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Agent, which maintains the learned (\"online\") critic network and the target critic network, to learn\n",
    "# the Q-value estimates, as well as the policy network, to learn to map a state to an action.\n",
    "\n",
    "UPDATE_EVERY = 20\n",
    "NB_UPDATES = 10\n",
    "LR_ACTOR = 1e-4\n",
    "LR_CRITIC = 1e-3\n",
    "TAU = 1e-2 # for soft update of target parameters\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "class Agent():\n",
    "    def __init__(self, batch_size, seed):\n",
    "        self.seed = random.seed(seed)\n",
    "        self.batch_size = batch_size\n",
    "        self.critic_target = Critic().to(device)\n",
    "        self.critic_online = Critic().to(device)\n",
    "        self.policy_target = Policy().to(device)\n",
    "        self.policy_online = Policy().to(device)\n",
    "        self.optimizer_critic = optim.Adam(self.critic_online.parameters(), lr=LR_CRITIC)\n",
    "        self.optimizer_policy = optim.Adam(self.policy_online.parameters(), lr=LR_ACTOR)\n",
    "        self.t_step = 0\n",
    "        self.experiences_buffer = deque(maxlen=BUFFER_SIZE)\n",
    "        self.noise = OUNoise(4, seed)\n",
    "        \n",
    "    def act(self, state, i_episode, add_noise=True):\n",
    "        self.policy_online.eval()\n",
    "        with torch.no_grad():\n",
    "            action = self.policy_online(state).cpu().data.numpy()\n",
    "        self.policy_online.train()\n",
    "        if add_noise:\n",
    "            action += self.noise.sample(0.999**i_episode)\n",
    "        return np.clip(action, -1, 1)    \n",
    "        \n",
    "    def step(self, state, action, next_state, reward, done):\n",
    "        self.experiences_buffer.append((state, action, next_state, reward, done))\n",
    "        self.t_step += 1\n",
    "        if (len(self.experiences_buffer) >= self.batch_size) and (self.t_step % UPDATE_EVERY == 0):\n",
    "            for j in range(NB_UPDATES):\n",
    "                experiences = self.collect_experiences()\n",
    "                self.learn(experiences, 0.99, self.t_step)\n",
    "            self.soft_update(self.critic_online, self.critic_target, TAU)\n",
    "            self.soft_update(self.policy_online, self.policy_target, TAU)\n",
    "            \n",
    "    def reset(self):\n",
    "        self.t_step = 0\n",
    "        self.noise.reset()\n",
    "            \n",
    "    def learn(self, experiences, gamma, t_step):\n",
    "        states = torch.from_numpy(np.vstack([e[0] for e in experiences])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e[1] for e in experiences])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e[2] for e in experiences])).float().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e[3] for e in experiences])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e[4] for e in experiences]).astype(np.uint8)).float().to(device)\n",
    "        \n",
    "        next_actions = self.policy_target(next_states).detach()\n",
    "        Q_target_next = self.critic_target(next_states, next_actions).detach()\n",
    "        Q_target = rewards + (gamma * Q_target_next * (1 - dones)).detach()\n",
    "        Q_online = self.critic_online(states, actions)\n",
    "        \n",
    "        loss_critic = F.mse_loss(Q_online, Q_target)\n",
    "        self.optimizer_critic.zero_grad()\n",
    "        loss_critic.backward()\n",
    "        self.optimizer_critic.step()\n",
    "        \n",
    "        predicted_actions = self.policy_online(states)\n",
    "        loss_policy = -self.critic_online(states, predicted_actions).mean()\n",
    "        self.optimizer_policy.zero_grad()\n",
    "        loss_policy.backward()\n",
    "        self.optimizer_policy.step()\n",
    "        \n",
    "        #if t_step % UPDATE_EVERY == 0:\n",
    "        #self.soft_update(self.critic_online, self.critic_target, TAU)\n",
    "        #self.soft_update(self.policy_online, self.policy_target, TAU)\n",
    "        \n",
    "    def collect_experiences(self):\n",
    "        experiences = random.choices(self.experiences_buffer, k=self.batch_size)\n",
    "        return experiences\n",
    "        \n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class OUNoise:\n",
    "    \"\"\"Ornstein-Uhlenbeck process.\"\"\"\n",
    "\n",
    "    def __init__(self, size, seed, mu=0., theta=0.15, sigma=0.2):\n",
    "        \"\"\"Initialize parameters and noise process.\"\"\"\n",
    "        self.mu = mu * np.ones(size)\n",
    "        self.theta = theta\n",
    "        self.sigma = sigma\n",
    "        self.seed = random.seed(seed)\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the internal state (= noise) to mean (mu).\"\"\"\n",
    "        self.state = copy.copy(self.mu)\n",
    "\n",
    "    def sample(self, decay_factor=1.0):\n",
    "        \"\"\"Update internal state and return it as a noise sample.\"\"\"\n",
    "        x = self.state\n",
    "        #dx = self.theta * (self.mu - x) + self.sigma * np.array([random.random() for i in range(len(x))])\n",
    "        dx = self.theta * (self.mu - x) + decay_factor * self.sigma * np.random.randn(len(x))\n",
    "        self.state = x + dx\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode(agent, i_episode, max_t):\n",
    "    env_info = env.reset(train_mode=True)[brain_name]\n",
    "    score = 0.0\n",
    "    state = torch.from_numpy(env_info.vector_observations).float().to(device)\n",
    "    for i in range(max_t):\n",
    "        action = agent.act(state, i_episode)\n",
    "        env_info = env.step(action)[brain_name]\n",
    "        next_state = torch.from_numpy(env_info.vector_observations).float().to(device)\n",
    "        reward = torch.FloatTensor(env_info.rewards).to(device)\n",
    "        done = torch.FloatTensor(env_info.local_done).to(device)\n",
    "        agent.step(state, action, next_state, reward, done)\n",
    "        score += reward.item() # assume 1 agent\n",
    "        state = next_state\n",
    "        if np.any(done):\n",
    "            #print(\"done after \", i ,\" episodes!\")\n",
    "            break\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "seed = 10\n",
    "agent = Agent(batch_size, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  0  - Score:  0.5299999881535769\n",
      "Episode  1  - Score:  0.4399999901652336\n",
      "Episode  2  - Score:  0.17999999597668648\n",
      "Episode  3  - Score:  1.0499999765306711\n",
      "Episode  4  - Score:  0.41999999061226845\n",
      "Episode  5  - Score:  2.539999943226576\n",
      "Episode  6  - Score:  2.249999949708581\n",
      "Episode  7  - Score:  0.7599999830126762\n",
      "Episode  8  - Score:  1.579999964684248\n",
      "Episode  9  - Score:  2.389999946579337\n",
      "Episode  10  - Score:  1.1399999745190144\n",
      "Episode  11  - Score:  1.6099999640136957\n",
      "Episode  12  - Score:  0.8999999798834324\n",
      "Episode  13  - Score:  1.8299999590963125\n",
      "Episode  14  - Score:  0.2199999950826168\n",
      "Episode  15  - Score:  0.24999999441206455\n",
      "Episode  16  - Score:  0.6299999859184027\n",
      "Episode  17  - Score:  0.6799999848008156\n",
      "Episode  18  - Score:  0.6499999854713678\n",
      "Episode  19  - Score:  1.6699999626725912\n",
      "Episode  20  - Score:  1.9899999555200338\n",
      "Episode  20  - Mean score:  1.12904759381\n",
      "Episode  21  - Score:  0.5799999870359898\n",
      "Episode  22  - Score:  0.8999999798834324\n",
      "Episode  23  - Score:  0.8999999798834324\n",
      "Episode  24  - Score:  1.5999999642372131\n",
      "Episode  25  - Score:  1.6799999624490738\n",
      "Episode  26  - Score:  2.059999953955412\n",
      "Episode  27  - Score:  1.7299999613314867\n",
      "Episode  28  - Score:  1.2599999718368053\n",
      "Episode  29  - Score:  0.7499999832361937\n",
      "Episode  30  - Score:  2.059999953955412\n",
      "Episode  31  - Score:  1.9999999552965164\n",
      "Episode  32  - Score:  1.4399999678134918\n",
      "Episode  33  - Score:  2.9599999338388443\n",
      "Episode  34  - Score:  3.039999932050705\n",
      "Episode  35  - Score:  2.299999948590994\n",
      "Episode  36  - Score:  4.669999895617366\n",
      "Episode  37  - Score:  2.5899999421089888\n",
      "Episode  38  - Score:  5.439999878406525\n",
      "Episode  39  - Score:  4.859999891370535\n",
      "Episode  40  - Score:  2.029999954625964\n",
      "Episode  40  - Mean score:  1.67219508457\n",
      "Episode  41  - Score:  6.459999855607748\n",
      "Episode  42  - Score:  3.0999999307096004\n",
      "Episode  43  - Score:  1.3799999691545963\n",
      "Episode  44  - Score:  5.589999875053763\n",
      "Episode  45  - Score:  7.369999835267663\n",
      "Episode  46  - Score:  5.509999876841903\n",
      "Episode  47  - Score:  4.029999909922481\n",
      "Episode  48  - Score:  1.7599999606609344\n",
      "Episode  49  - Score:  3.4399999231100082\n",
      "Episode  50  - Score:  4.739999894052744\n",
      "Episode  51  - Score:  4.429999900981784\n",
      "Episode  52  - Score:  4.099999908357859\n",
      "Episode  53  - Score:  2.4499999452382326\n",
      "Episode  54  - Score:  4.449999900534749\n",
      "Episode  55  - Score:  4.769999893382192\n",
      "Episode  56  - Score:  4.899999890476465\n",
      "Episode  57  - Score:  3.589999919757247\n",
      "Episode  58  - Score:  7.199999839067459\n",
      "Episode  59  - Score:  2.7399999387562275\n",
      "Episode  60  - Score:  5.369999879971147\n",
      "Episode  60  - Mean score:  2.55639338548\n",
      "Episode  61  - Score:  7.7899998258799314\n",
      "Episode  62  - Score:  6.219999860972166\n",
      "Episode  63  - Score:  7.27999983727932\n",
      "Episode  64  - Score:  7.219999838620424\n",
      "Episode  65  - Score:  11.199999749660492\n",
      "Episode  66  - Score:  7.879999823868275\n",
      "Episode  67  - Score:  11.749999737367034\n",
      "Episode  68  - Score:  4.60999989695847\n",
      "Episode  69  - Score:  6.829999847337604\n",
      "Episode  70  - Score:  6.2099998611956835\n",
      "Episode  71  - Score:  8.979999799281359\n",
      "Episode  72  - Score:  4.8699998911470175\n",
      "Episode  73  - Score:  6.5199998542666435\n",
      "Episode  74  - Score:  4.559999898076057\n",
      "Episode  75  - Score:  11.689999738708138\n",
      "Episode  76  - Score:  6.319999858736992\n",
      "Episode  77  - Score:  8.189999816939235\n",
      "Episode  78  - Score:  5.119999885559082\n",
      "Episode  79  - Score:  14.529999675229192\n",
      "Episode  80  - Score:  8.299999814480543\n",
      "Episode  80  - Mean score:  3.85197522254\n",
      "Episode  81  - Score:  11.709999738261104\n",
      "Episode  82  - Score:  12.54999971948564\n",
      "Episode  83  - Score:  9.289999792352319\n",
      "Episode  84  - Score:  8.999999798834324\n",
      "Episode  85  - Score:  9.05999979749322\n",
      "Episode  86  - Score:  11.03999975323677\n",
      "Episode  87  - Score:  10.019999776035547\n",
      "Episode  88  - Score:  11.84999973513186\n",
      "Episode  89  - Score:  7.269999837502837\n",
      "Episode  90  - Score:  9.129999795928597\n",
      "Episode  91  - Score:  10.949999755248427\n",
      "Episode  92  - Score:  10.819999758154154\n",
      "Episode  93  - Score:  11.329999746754766\n",
      "Episode  94  - Score:  13.189999705180526\n",
      "Episode  95  - Score:  8.179999817162752\n",
      "Episode  96  - Score:  6.829999847337604\n",
      "Episode  97  - Score:  12.599999718368053\n",
      "Episode  98  - Score:  6.439999856054783\n",
      "Episode  99  - Score:  4.929999889805913\n",
      "Episode  100  - Score:  5.739999871701002\n",
      "Episode  100  - Mean score:  5.03409988748\n",
      "Episode  101  - Score:  10.389999767765403\n",
      "Episode  102  - Score:  8.319999814033508\n",
      "Episode  103  - Score:  9.479999788105488\n",
      "Episode  104  - Score:  9.169999795034528\n",
      "Episode  105  - Score:  5.2999998815357685\n",
      "Episode  106  - Score:  9.419999789446592\n",
      "Episode  107  - Score:  16.239999637007713\n",
      "Episode  108  - Score:  6.069999864324927\n",
      "Episode  109  - Score:  10.049999775364995\n",
      "Episode  110  - Score:  11.709999738261104\n",
      "Episode  111  - Score:  14.319999679923058\n",
      "Episode  112  - Score:  12.609999718144536\n",
      "Episode  113  - Score:  8.309999814257026\n",
      "Episode  114  - Score:  8.119999818503857\n",
      "Episode  115  - Score:  16.049999641254544\n",
      "Episode  116  - Score:  14.419999677687883\n",
      "Episode  117  - Score:  10.849999757483602\n",
      "Episode  118  - Score:  13.12999970652163\n",
      "Episode  119  - Score:  5.979999866336584\n",
      "Episode  120  - Score:  12.15999972820282\n",
      "Episode  120  - Mean score:  6.92329984525\n",
      "Episode  121  - Score:  14.089999685063958\n",
      "Episode  122  - Score:  10.499999765306711\n",
      "Episode  123  - Score:  10.56999976374209\n",
      "Episode  124  - Score:  14.36999967880547\n",
      "Episode  125  - Score:  13.66999969445169\n",
      "Episode  126  - Score:  13.059999708086252\n",
      "Episode  127  - Score:  12.179999727755785\n",
      "Episode  128  - Score:  9.049999797716737\n",
      "Episode  129  - Score:  15.409999655559659\n",
      "Episode  130  - Score:  9.129999795928597\n",
      "Episode  131  - Score:  9.649999784305692\n",
      "Episode  132  - Score:  13.47999969869852\n",
      "Episode  133  - Score:  21.21999952569604\n",
      "Episode  134  - Score:  6.919999845325947\n",
      "Episode  135  - Score:  12.599999718368053\n",
      "Episode  136  - Score:  13.639999695122242\n",
      "Episode  137  - Score:  16.589999629184604\n",
      "Episode  138  - Score:  14.55999967455864\n",
      "Episode  139  - Score:  12.50999972037971\n",
      "Episode  140  - Score:  11.649999739602208\n",
      "Episode  140  - Mean score:  9.02329979831\n",
      "Episode  141  - Score:  18.449999587610364\n",
      "Episode  142  - Score:  8.859999801963568\n",
      "Episode  143  - Score:  18.66999958269298\n",
      "Episode  144  - Score:  16.869999622926116\n",
      "Episode  145  - Score:  5.009999888017774\n",
      "Episode  146  - Score:  14.579999674111605\n",
      "Episode  147  - Score:  11.5399997420609\n",
      "Episode  148  - Score:  19.55999956279993\n",
      "Episode  149  - Score:  18.659999582916498\n",
      "Episode  150  - Score:  17.289999613538384\n",
      "Episode  151  - Score:  19.67999956011772\n",
      "Episode  152  - Score:  15.709999648854136\n",
      "Episode  153  - Score:  21.669999515637755\n",
      "Episode  154  - Score:  23.979999464005232\n",
      "Episode  155  - Score:  9.299999792128801\n",
      "Episode  156  - Score:  20.82999953441322\n",
      "Episode  157  - Score:  16.84999962337315\n",
      "Episode  158  - Score:  19.029999574646354\n",
      "Episode  159  - Score:  28.279999367892742\n",
      "Episode  160  - Score:  18.12999959476292\n",
      "Episode  160  - Mean score:  11.5789997412\n",
      "Episode  161  - Score:  25.44999943114817\n",
      "Episode  162  - Score:  19.90999955497682\n",
      "Episode  163  - Score:  16.53999963030219\n",
      "Episode  164  - Score:  24.81999944522977\n",
      "Episode  165  - Score:  34.34999923221767\n",
      "Episode  166  - Score:  24.189999459311366\n",
      "Episode  167  - Score:  19.86999955587089\n",
      "Episode  168  - Score:  29.9699993301183\n",
      "Episode  169  - Score:  26.71999940276146\n",
      "Episode  170  - Score:  22.02999950759113\n",
      "Episode  171  - Score:  26.869999399408698\n",
      "Episode  172  - Score:  25.509999429807067\n",
      "Episode  173  - Score:  28.359999366104603\n",
      "Episode  174  - Score:  28.689999358728528\n",
      "Episode  175  - Score:  27.819999378174543\n",
      "Episode  176  - Score:  30.879999309778214\n",
      "Episode  177  - Score:  26.59999940544367\n",
      "Episode  178  - Score:  28.249999368563294\n",
      "Episode  179  - Score:  33.81999924406409\n",
      "Episode  180  - Score:  35.39999920874834\n",
      "Episode  180  - Mean score:  15.3787996563\n",
      "Episode  181  - Score:  32.21999927982688\n",
      "Episode  182  - Score:  25.529999429360032\n",
      "Episode  183  - Score:  28.799999356269836\n",
      "Episode  184  - Score:  28.679999358952045\n",
      "Episode  185  - Score:  35.12999921478331\n",
      "Episode  186  - Score:  32.72999926842749\n",
      "Episode  187  - Score:  34.41999923065305\n",
      "Episode  188  - Score:  33.64999924786389\n",
      "Episode  189  - Score:  34.639999225735664\n",
      "Episode  190  - Score:  18.989999575540423\n",
      "Episode  191  - Score:  31.609999293461442\n",
      "Episode  192  - Score:  37.66999915800989\n",
      "Episode  193  - Score:  30.8299993108958\n",
      "Episode  194  - Score:  28.53999936208129\n",
      "Episode  195  - Score:  37.17999916896224\n",
      "Episode  196  - Score:  23.149999482557178\n",
      "Episode  197  - Score:  39.50999911688268\n",
      "Episode  198  - Score:  33.709999246522784\n",
      "Episode  199  - Score:  33.03999926149845\n",
      "Episode  200  - Score:  21.25999952480197\n",
      "Episode  200  - Mean score:  19.6723995603\n",
      "Episode  201  - Score:  32.1499992813915\n",
      "Episode  202  - Score:  32.55999927222729\n",
      "Episode  203  - Score:  31.009999306872487\n",
      "Episode  204  - Score:  32.47999927401543\n",
      "Episode  205  - Score:  39.059999126940966\n",
      "Episode  206  - Score:  29.43999934196472\n",
      "Episode  207  - Score:  30.139999326318502\n",
      "Episode  208  - Score:  34.059999238699675\n",
      "Episode  209  - Score:  27.179999392479658\n",
      "Episode  210  - Score:  33.64999924786389\n",
      "Episode  211  - Score:  20.649999538436532\n",
      "Episode  212  - Score:  26.389999410137534\n",
      "Episode  213  - Score:  31.319999299943447\n",
      "Episode  214  - Score:  35.74999920092523\n",
      "Episode  215  - Score:  32.669999269768596\n",
      "Episode  216  - Score:  35.13999921455979\n",
      "Episode  217  - Score:  35.82999919913709\n",
      "Episode  218  - Score:  38.56999913789332\n",
      "Episode  219  - Score:  31.739999290555716\n",
      "Episode  220  - Score:  30.189999325200915\n",
      "Episode  220  - Mean score:  23.9511994646\n",
      "Episode  221  - Score:  38.199999146163464\n",
      "Episode  222  - Score:  24.23999945819378\n",
      "Episode  223  - Score:  17.529999608173966\n",
      "Episode  224  - Score:  35.879999198019505\n",
      "Episode  225  - Score:  37.82999915443361\n",
      "Episode  226  - Score:  26.05999941751361\n",
      "Episode  227  - Score:  31.629999293014407\n",
      "Episode  228  - Score:  37.239999167621136\n",
      "Episode  229  - Score:  19.299999568611383\n",
      "Episode  230  - Score:  34.18999923579395\n",
      "Episode  231  - Score:  19.67999956011772\n",
      "Episode  232  - Score:  25.459999430924654\n",
      "Episode  233  - Score:  24.879999443888664\n",
      "Episode  234  - Score:  34.04999923892319\n",
      "Episode  235  - Score:  29.289999345317483\n",
      "Episode  236  - Score:  21.599999517202377\n",
      "Episode  237  - Score:  32.22999927960336\n",
      "Episode  238  - Score:  35.36999920941889\n",
      "Episode  239  - Score:  36.82999917678535\n",
      "Episode  240  - Score:  27.099999394267797\n",
      "Episode  240  - Mean score:  27.2885993901\n",
      "Episode  241  - Score:  36.079999193549156\n",
      "Episode  242  - Score:  33.019999261945486\n",
      "Episode  243  - Score:  23.35999947786331\n",
      "Episode  244  - Score:  29.759999334812164\n",
      "Episode  245  - Score:  33.03999926149845\n",
      "Episode  246  - Score:  23.439999476075172\n",
      "Episode  247  - Score:  37.549999160692096\n",
      "Episode  248  - Score:  25.579999428242445\n",
      "Episode  249  - Score:  30.94999930821359\n",
      "Episode  250  - Score:  23.709999470040202\n",
      "Episode  251  - Score:  27.859999377280474\n",
      "Episode  252  - Score:  32.1499992813915\n",
      "Episode  253  - Score:  35.39999920874834\n",
      "Episode  254  - Score:  32.82999926619232\n",
      "Episode  255  - Score:  32.51999927312136\n",
      "Episode  256  - Score:  29.789999334141612\n",
      "Episode  257  - Score:  30.339999321848154\n",
      "Episode  258  - Score:  35.7099992018193\n",
      "Episode  259  - Score:  31.01999930664897\n",
      "Episode  260  - Score:  33.249999256804585\n",
      "Episode  260  - Mean score:  30.0326993287\n",
      "Problem solved!\n",
      "Episode  261  - Score:  39.06999912671745\n",
      "Problem solved!\n",
      "Episode  262  - Score:  30.35999932140112\n",
      "Problem solved!\n",
      "Episode  263  - Score:  33.399999253451824\n",
      "Problem solved!\n",
      "Episode  264  - Score:  26.629999404773116\n",
      "Problem solved!\n",
      "Episode  265  - Score:  36.29999918863177\n",
      "Problem solved!\n",
      "Episode  266  - Score:  34.679999224841595\n",
      "Problem solved!\n",
      "Episode  267  - Score:  34.57999922707677\n",
      "Problem solved!\n",
      "Episode  268  - Score:  35.61999920383096\n",
      "Problem solved!\n",
      "Episode  269  - Score:  32.30999927781522\n",
      "Problem solved!\n",
      "Episode  270  - Score:  27.30999938957393\n",
      "Problem solved!\n",
      "Episode  271  - Score:  25.40999943204224\n",
      "Problem solved!\n",
      "Episode  272  - Score:  23.139999482780695\n",
      "Problem solved!\n",
      "Episode  273  - Score:  34.18999923579395\n",
      "Problem solved!\n",
      "Episode  274  - Score:  24.919999442994595\n",
      "Problem solved!\n",
      "Episode  275  - Score:  34.18999923579395\n",
      "Problem solved!\n",
      "Episode  276  - Score:  34.58999922685325\n",
      "Problem solved!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-7e6da220c19c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_episodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mepisode_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mlast_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmean_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-4ab0a78183d6>\u001b[0m in \u001b[0;36mrun_episode\u001b[0;34m(agent, i_episode, max_t)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_done\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# assume 1 agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-91f8384653f9>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, state, action, next_state, reward, done)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNB_UPDATES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mexperiences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_experiences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoft_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_online\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTAU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoft_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_online\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTAU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-91f8384653f9>\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, experiences, gamma, t_step)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mnext_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mdones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36matleast_2d\u001b[0;34m(*arys)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mary\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \"\"\"\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;31m# Numpy array interface, to support `numpy.asarray(tensor) -> ndarray`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_episodes = 300\n",
    "max_t = 1000\n",
    "all_scores = []\n",
    "last_scores = deque(maxlen=100)\n",
    "for i in range(n_episodes):\n",
    "    agent.reset()\n",
    "    episode_score = run_episode(agent, i, max_t)\n",
    "    last_scores.append(episode_score)\n",
    "    mean_score = np.mean(np.array(last_scores))\n",
    "    all_scores.append(episode_score)\n",
    "    print(\"Episode \", i, \" - Score: \", episode_score)\n",
    "    if i > 0 and i % 20 == 0:\n",
    "        print(\"Episode \", i, \" - Mean score: \", mean_score)\n",
    "    if i > 100 and mean_score >= 30:\n",
    "        print(\"Problem solved!\")\n",
    "    torch.save(agent.policy_online.state_dict(), 'checkpoint_policy.pth')\n",
    "    torch.save(agent.critic_online.state_dict(), 'checkpoint_critic.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8aa1bb1a90>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(all_scores)+1), all_scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(agent.policy_online.state_dict(), 'checkpoint_policy_20210724.pth')\n",
    "torch.save(agent.critic_online.state_dict(), 'checkpoint_critic_20210724.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
